<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorial on AIShell &mdash; Wenet  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pretrained Models in WeNet" href="pretrained_models.html" />
    <link rel="prev" title="Tutorial on LibriSpeech" href="tutorial_librispeech.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Wenet
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="python_binding.html">WeNet Python Binding</a></li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">Papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_librispeech.html">Tutorial on LibriSpeech</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorial on AIShell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#setup-environment">Setup environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#first-experiment">First Experiment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stage-1-download-data">Stage -1: Download data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-0-prepare-training-data">Stage 0: Prepare Training data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-1-extract-optinal-cmvn-features">Stage 1: Extract optinal cmvn features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-2-generate-label-token-dictionary">Stage 2: Generate label token dictionary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-3-prepare-wenet-data-format">Stage 3: Prepare WeNet data format</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-4-neural-network-training">Stage 4: Neural Network training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-5-recognize-wav-using-the-trained-model">Stage 5: Recognize wav using the trained model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stage-6-export-the-trained-model">Stage 6: Export the trained model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Pretrained Models in WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="lm.html">LM for WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="context.html">Context Biasing</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Runtime for WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit_in_wenet.html">JIT in WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="UIO.html">UIO for WeNet</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Wenet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Tutorial on AIShell</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tutorial_aishell.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="tutorial-on-aishell">
<h1>Tutorial on AIShell<a class="headerlink" href="#tutorial-on-aishell" title="Permalink to this headline"></a></h1>
<p>If you meet any problems when going through this tutorial, please feel free to ask in github <a class="reference external" href="https://github.com/mobvoi/wenet/issues">issues</a>. Thanks for any kind of feedback.</p>
<div class="section" id="setup-environment">
<h2>Setup environment<a class="headerlink" href="#setup-environment" title="Permalink to this headline"></a></h2>
<p>Please follow <a class="reference external" href="https://github.com/wenet-e2e/wenet#installation">Installation</a> to install WeNet.</p>
</div>
<div class="section" id="first-experiment">
<h2>First Experiment<a class="headerlink" href="#first-experiment" title="Permalink to this headline"></a></h2>
<p>We provide a recipe <code class="docutils literal notranslate"><span class="pre">example/aishell/s0/run.sh</span></code> on aishell-1 data.</p>
<p>The recipe is simple and we suggest you run each stage one by one manually and check the result to understand the whole process.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">example</span><span class="o">/</span><span class="n">aishell</span><span class="o">/</span><span class="n">s0</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="o">-</span><span class="mi">1</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">0</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">0</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">1</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">1</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">2</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">2</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">3</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">3</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">4</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">4</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">5</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">5</span>
<span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="mi">6</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">6</span>
</pre></div>
</div>
<p>You could also just run the whole script</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">stage</span> <span class="o">-</span><span class="mi">1</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">stage</span> <span class="mi">6</span>
</pre></div>
</div>
<div class="section" id="stage-1-download-data">
<h3>Stage -1: Download data<a class="headerlink" href="#stage-1-download-data" title="Permalink to this headline"></a></h3>
<p>This stage downloads the aishell-1 data to the local path <code class="docutils literal notranslate"><span class="pre">$data</span></code>. This may take several hours. If you have already downloaded the data, please change the <code class="docutils literal notranslate"><span class="pre">$data</span></code> variable in <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> and start from <code class="docutils literal notranslate"><span class="pre">--stage</span> <span class="pre">0</span></code>.
Please set a <strong>absolute path</strong> for <code class="docutils literal notranslate"><span class="pre">$data</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">/home/username/asr-data/aishell/</span></code></p>
</div>
<div class="section" id="stage-0-prepare-training-data">
<h3>Stage 0: Prepare Training data<a class="headerlink" href="#stage-0-prepare-training-data" title="Permalink to this headline"></a></h3>
<p>In this stage, <code class="docutils literal notranslate"><span class="pre">local/aishell_data_prep.sh</span></code> organizes the original aishell-1 data into two files:</p>
<ul class="simple">
<li><p><strong>wav.scp</strong> each line records two tab-separated columns : <code class="docutils literal notranslate"><span class="pre">wav_id</span></code> and <code class="docutils literal notranslate"><span class="pre">wav_path</span></code></p></li>
<li><p><strong>text</strong>  each line records two tab-separated columns :  <code class="docutils literal notranslate"><span class="pre">wav_id</span></code> and <code class="docutils literal notranslate"><span class="pre">text_label</span></code></p></li>
</ul>
<p><strong>wav.scp</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">BAC009S0002W0122</span> <span class="o">/</span><span class="n">export</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">OpenSLR</span><span class="o">/</span><span class="mi">33</span><span class="o">/</span><span class="n">data_aishell</span><span class="o">/</span><span class="n">wav</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="n">S0002</span><span class="o">/</span><span class="n">BAC009S0002W0122</span><span class="o">.</span><span class="n">wav</span>
<span class="n">BAC009S0002W0123</span> <span class="o">/</span><span class="n">export</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">OpenSLR</span><span class="o">/</span><span class="mi">33</span><span class="o">/</span><span class="n">data_aishell</span><span class="o">/</span><span class="n">wav</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="n">S0002</span><span class="o">/</span><span class="n">BAC009S0002W0123</span><span class="o">.</span><span class="n">wav</span>
<span class="n">BAC009S0002W0124</span> <span class="o">/</span><span class="n">export</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">OpenSLR</span><span class="o">/</span><span class="mi">33</span><span class="o">/</span><span class="n">data_aishell</span><span class="o">/</span><span class="n">wav</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="n">S0002</span><span class="o">/</span><span class="n">BAC009S0002W0124</span><span class="o">.</span><span class="n">wav</span>
<span class="n">BAC009S0002W0125</span> <span class="o">/</span><span class="n">export</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">OpenSLR</span><span class="o">/</span><span class="mi">33</span><span class="o">/</span><span class="n">data_aishell</span><span class="o">/</span><span class="n">wav</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="n">S0002</span><span class="o">/</span><span class="n">BAC009S0002W0125</span><span class="o">.</span><span class="n">wav</span>
<span class="o">...</span>
</pre></div>
</div>
<p><strong>text</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">BAC009S0002W0122</span> <span class="n">而对楼市成交抑制作用最大的限购</span>
<span class="n">BAC009S0002W0123</span> <span class="n">也成为地方政府的眼中钉</span>
<span class="n">BAC009S0002W0124</span> <span class="n">自六月底呼和浩特市率先宣布取消限购后</span>
<span class="n">BAC009S0002W0125</span> <span class="n">各地政府便纷纷跟进</span>
<span class="o">...</span>
</pre></div>
</div>
<p>If you want to train using your customized data, just organize the data into two files <code class="docutils literal notranslate"><span class="pre">wav.scp</span></code> and <code class="docutils literal notranslate"><span class="pre">text</span></code>, and start from <code class="docutils literal notranslate"><span class="pre">stage</span> <span class="pre">1</span></code>.</p>
</div>
<div class="section" id="stage-1-extract-optinal-cmvn-features">
<h3>Stage 1: Extract optinal cmvn features<a class="headerlink" href="#stage-1-extract-optinal-cmvn-features" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">example/aishell/s0</span></code> uses raw wav as input and and <a class="reference external" href="https://pytorch.org/audio/stable/index.html">TorchAudio</a> to extract the features just-in-time in dataloader. So in this step we just copy the training wav.scp and text file into the <code class="docutils literal notranslate"><span class="pre">raw_wav/train/</span></code> dir.</p>
<p><code class="docutils literal notranslate"><span class="pre">tools/compute_cmvn_stats.py</span></code> is used to extract global cmvn(cepstral mean and variance normalization) statistics. These statistics will be used to normalize the acoustic features. Setting <code class="docutils literal notranslate"><span class="pre">cmvn=false</span></code> will skip this step.</p>
</div>
<div class="section" id="stage-2-generate-label-token-dictionary">
<h3>Stage 2: Generate label token dictionary<a class="headerlink" href="#stage-2-generate-label-token-dictionary" title="Permalink to this headline"></a></h3>
<p>The dict is a map between label tokens (we use characters for Aishell-1) and
the integer indices.</p>
<p>An example dict is as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">blank</span><span class="o">&gt;</span> <span class="mi">0</span>
<span class="o">&lt;</span><span class="n">unk</span><span class="o">&gt;</span> <span class="mi">1</span>
<span class="n">一</span> <span class="mi">2</span>
<span class="n">丁</span> <span class="mi">3</span>
<span class="o">...</span>
<span class="n">龚</span> <span class="mi">4230</span>
<span class="n">龟</span> <span class="mi">4231</span>
<span class="o">&lt;</span><span class="n">sos</span><span class="o">/</span><span class="n">eos</span><span class="o">&gt;</span> <span class="mi">4232</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;blank&gt;</span></code> denotes the blank symbol for CTC.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;unk&gt;</span></code> denotes the unknown token, any out-of-vocabulary tokens will be mapped into it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;sos/eos&gt;</span></code> denotes start-of-speech and end-of-speech symbols for attention based encoder decoder training, and they shares the same id.</p></li>
</ul>
</div>
<div class="section" id="stage-3-prepare-wenet-data-format">
<h3>Stage 3: Prepare WeNet data format<a class="headerlink" href="#stage-3-prepare-wenet-data-format" title="Permalink to this headline"></a></h3>
<p>This stage generates the WeNet required format file <code class="docutils literal notranslate"><span class="pre">data.list</span></code>. Each line in <code class="docutils literal notranslate"><span class="pre">data.list</span></code> is in json format which contains the following fields.</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">key</span></code>: key of the utterance</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wav</span></code>: audio file path of the utterance</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">txt</span></code>: normalized transcription of the utterance, the transcription will be tokenized to the model units on-the-fly at the training stage.</p></li>
</ol>
<p>Here is an example of the <code class="docutils literal notranslate"><span class="pre">data.list</span></code>, and please see the generated training feature file in <code class="docutils literal notranslate"><span class="pre">data/train/data.list</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;BAC009S0002W0122&quot;</span><span class="p">,</span> <span class="s2">&quot;wav&quot;</span><span class="p">:</span> <span class="s2">&quot;/export/data/asr-data/OpenSLR/33//data_aishell/wav/train/S0002/BAC009S0002W0122.wav&quot;</span><span class="p">,</span> <span class="s2">&quot;txt&quot;</span><span class="p">:</span> <span class="s2">&quot;而对楼市成交抑制作用最大的限购&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;BAC009S0002W0123&quot;</span><span class="p">,</span> <span class="s2">&quot;wav&quot;</span><span class="p">:</span> <span class="s2">&quot;/export/data/asr-data/OpenSLR/33//data_aishell/wav/train/S0002/BAC009S0002W0123.wav&quot;</span><span class="p">,</span> <span class="s2">&quot;txt&quot;</span><span class="p">:</span> <span class="s2">&quot;也成为地方政府的眼中钉&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;BAC009S0002W0124&quot;</span><span class="p">,</span> <span class="s2">&quot;wav&quot;</span><span class="p">:</span> <span class="s2">&quot;/export/data/asr-data/OpenSLR/33//data_aishell/wav/train/S0002/BAC009S0002W0124.wav&quot;</span><span class="p">,</span> <span class="s2">&quot;txt&quot;</span><span class="p">:</span> <span class="s2">&quot;自六月底呼和浩特市率先宣布取消限购后&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p>We aslo design another format for <code class="docutils literal notranslate"><span class="pre">data.list</span></code> named <code class="docutils literal notranslate"><span class="pre">shard</span></code> which is for big data training.
Please see <a class="reference external" href="https://github.com/wenet-e2e/wenet/tree/main/examples/gigaspeech/s0">gigaspeech</a>(10k hours) or
<a class="reference external" href="https://github.com/wenet-e2e/wenet/tree/main/examples/wenetspeech/s0">wenetspeech</a>(10k hours)
for how to use <code class="docutils literal notranslate"><span class="pre">shard</span></code> style <code class="docutils literal notranslate"><span class="pre">data.list</span></code> if you want to apply WeNet on big data set(more than 5k).</p>
</div>
<div class="section" id="stage-4-neural-network-training">
<h3>Stage 4: Neural Network training<a class="headerlink" href="#stage-4-neural-network-training" title="Permalink to this headline"></a></h3>
<p>The NN model is trained in this step.</p>
<ul class="simple">
<li><p>Multi-GPU mode</p></li>
</ul>
<p>If using DDP mode for multi-GPU, we suggest using <code class="docutils literal notranslate"><span class="pre">dist_backend=&quot;nccl&quot;</span></code>. If the NCCL does not work, try using <code class="docutils literal notranslate"><span class="pre">gloo</span></code> or use <code class="docutils literal notranslate"><span class="pre">torch==1.6.0</span></code>
Set the GPU ids in CUDA_VISIBLE_DEVICES. For example, set <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">CUDA_VISIBLE_DEVICES=&quot;0,1,2,3,6,7&quot;</span></code> to use card 0,1,2,3,6,7.</p>
<ul class="simple">
<li><p>Resume training</p></li>
</ul>
<p>If your experiment is terminated after running several epochs for some reasons (e.g. the GPU is accidentally used by other people and is out-of-memory ), you could continue the training from a checkpoint model. Just find out the finished epoch in <code class="docutils literal notranslate"><span class="pre">exp/your_exp/</span></code>, set  <code class="docutils literal notranslate"><span class="pre">checkpoint=exp/your_exp/$n.pt</span></code> and run the <code class="docutils literal notranslate"><span class="pre">run.sh</span> <span class="pre">--stage</span> <span class="pre">4</span></code>. Then the training will continue from the $n+1.pt</p>
<ul class="simple">
<li><p>Config</p></li>
</ul>
<p>The config of neural network structure, optimization parameter, loss parameters, and dataset can be set in a YAML format file.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">conf/</span></code>,  we provide several models like transformer and conformer. see <code class="docutils literal notranslate"><span class="pre">conf/train_conformer.yaml</span></code> for reference.</p>
<ul class="simple">
<li><p>Use Tensorboard</p></li>
</ul>
<p>The training takes several hours. The actual time depends on the number and type of your GPU cards. In an 8-card 2080 Ti machine, it takes about less than one day for 50 epochs.
You could use tensorboard to monitor the loss.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tensorboard --logdir tensorboard/$your_exp_name/ --port 12598 --bind_all
</pre></div>
</div>
</div>
<div class="section" id="stage-5-recognize-wav-using-the-trained-model">
<h3>Stage 5: Recognize wav using the trained model<a class="headerlink" href="#stage-5-recognize-wav-using-the-trained-model" title="Permalink to this headline"></a></h3>
<p>This stage shows how to recognize a set of wavs into texts. It also shows how to do the model averaging.</p>
<ul class="simple">
<li><p>Average model</p></li>
</ul>
<p>If <code class="docutils literal notranslate"><span class="pre">${average_checkpoint}</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the best <code class="docutils literal notranslate"><span class="pre">${average_num}</span></code> models on cross validation set will be averaged to generate a boosted model and used for recognition.</p>
<ul class="simple">
<li><p>Decoding</p></li>
</ul>
<p>Recognition is also called decoding or inference. The function of the NN will be applied on the input acoustic feature sequence to output a sequence of text.</p>
<p>Four decoding methods are provided in WeNet:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ctc_greedy_search</span></code> : encoder + CTC greedy search</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ctc_prefix_beam_search</span></code> :  encoder + CTC prefix beam search</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attention</span></code> : encoder + attention-based decoder decoding</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attention_rescoring</span></code> : rescoring the ctc candidates from ctc prefix beam search with encoder output on attention-based decoder.</p></li>
</ul>
<p>In general, attention_rescoring is the best method. Please see <a class="reference external" href="https://arxiv.org/pdf/2012.05481.pdf">U2 paper</a> for the details of these algorithms.</p>
<p><code class="docutils literal notranslate"><span class="pre">--beam_size</span></code> is a tunable parameter, a large beam size may get better results but also cause higher computation cost.</p>
<p><code class="docutils literal notranslate"><span class="pre">--batch_size</span></code> can be greater than 1 for “ctc_greedy_search” and “attention” decoding mode, and must be 1 for “ctc_prefix_beam_search” and “attention_rescoring” decoding mode.</p>
<ul class="simple">
<li><p>WER evaluation</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">tools/compute-wer.py</span></code> will calculate the word (or char) error rate of the result. If you run the recipe without any change, you may get WER ~= 5%.</p>
</div>
<div class="section" id="stage-6-export-the-trained-model">
<h3>Stage 6: Export the trained model<a class="headerlink" href="#stage-6-export-the-trained-model" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">wenet/bin/export_jit.py</span></code> will export the trained model using Libtorch. The exported model files can be easily used for inference in other programming languages such as C++.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tutorial_librispeech.html" class="btn btn-neutral float-left" title="Tutorial on LibriSpeech" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pretrained_models.html" class="btn btn-neutral float-right" title="Pretrained Models in WeNet" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, wenet-team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>